{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d8ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import scipy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from rbms.dataset import load_dataset\n",
    "\n",
    "from rbms.bernoulli_bernoulli.functional import init_chains\n",
    "from rbms.sampling.gibbs import sample_state\n",
    "from rbms.io import load_model\n",
    "from rbms.utils import get_saved_updates\n",
    "from rbms.bernoulli_bernoulli.classes import BBRBM\n",
    "from rbms.utils import compute_log_likelihood\n",
    "from rbms.io import load_params\n",
    "from rbms.plot import plot_PCA\n",
    "from rbms.utils import get_flagged_updates\n",
    "from rbms.utils import get_eigenvalues_history\n",
    "\n",
    "from fastrbm.trajectory.pt import ptt_sampling, init_sampling\n",
    "from fastrbm.io import load_rcm\n",
    "from fastrbm.trajectory.partition_function import compute_partition_function_ptt\n",
    "\n",
    "device = \"cuda\"\n",
    "dtype = torch.float32\n",
    "\n",
    "# use LaTeX fonts in the plots\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"stix\"\n",
    "plt.rcParams[\"font.family\"] = \"STIXGeneral\"\n",
    "plt.rcParams.update({\"font.size\": 15})\n",
    "plt.rcParams[\"text.usetex\"] = True\n",
    "plt.rcParams[\"text.latex.preamble\"] = r\"\\usepackage{bm}\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e61e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, _ = load_dataset(\n",
    "    \"../../data/MNIST_train.h5\",\n",
    "    subset_labels=[0, 1],\n",
    "    train_size=1.0,\n",
    "    device=device,\n",
    "    dtype=dtype,\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187cf92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../../output/rbm/MNIST01_012_wb_PCD_test.h5\"\n",
    "\n",
    "\n",
    "import rbms\n",
    "import rbms.parser\n",
    "updates = get_saved_updates(filename)\n",
    "params, chains, t, hyperparameters = load_model(filename, updates[-1], device, dtype)\n",
    "print(hyperparameters)\n",
    "\n",
    "rng = np.random.default_rng(hyperparameters[\"seed\"])\n",
    "train_dataset, test_dataset = dataset.split_train_test(rng, hyperparameters[\"train_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b84b837",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_dataset.data.to(device).float()\n",
    "\n",
    "U_data, S_data, V_dataT = torch.linalg.svd(data - data.mean(0))\n",
    "data_proj = data @ V_dataT.mT\n",
    "data_proj = data_proj.cpu().numpy()\n",
    "pc_proj = chains[\"visible\"] @ V_dataT.mT\n",
    "pc_proj = pc_proj.cpu().numpy()\n",
    "\n",
    "\n",
    "for dir1 in range(0, 5, 2):\n",
    "    plot_PCA(\n",
    "        data_proj,\n",
    "        pc_proj,\n",
    "        labels=[\"dataset\", \"Permanent chains\"],\n",
    "        dir1=dir1,\n",
    "        dir2=dir1 + 1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de58cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "updates = get_saved_updates(filename)\n",
    "\n",
    "print(updates)\n",
    "params, chains, t, hyperparameters = load_model(filename, updates[0], device, dtype)\n",
    "print(t)\n",
    "w, vbias, hbias = params.weight_matrix, params.vbias, params.hbias\n",
    "print(hyperparameters[\"learning_rate\"])\n",
    "params.hbias.shape\n",
    "\n",
    "ptt_updates = get_flagged_updates(filename, \"ptt\")\n",
    "print(ptt_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ee3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_eigenvalues_history(filename)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(x, y)\n",
    "for i in range(len(ptt_updates)):\n",
    "    plt.vlines(ptt_updates[i], 0, y.max(), color=\"grey\", linestyles=\"dashed\")\n",
    "ax.semilogx()\n",
    "ax.set_title(r\"Singular values of $\\bm W$\")\n",
    "ax.set_xlabel(\"Training time (gradient updates)\")\n",
    "ax.set_ylabel(r\"$\\bm w$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0e55b",
   "metadata": {},
   "source": [
    "# Parallel Trajectory Tempering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e838264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the RCM to sample the first model\n",
    "rcm = load_rcm(filename, device=device, dtype=dtype)\n",
    "\n",
    "# Load the parameters saved during training\n",
    "list_params = []\n",
    "for upd in updates:\n",
    "    list_params.append(load_params(filename, upd, device, dtype))\n",
    "\n",
    "# Perform an annealing to initialize the chains \n",
    "list_chains = init_sampling(2000, list_params, device=device, dtype=dtype, rcm=rcm)\n",
    "\n",
    "# PTT Sampling\n",
    "list_chains, _, _ = ptt_sampling(\n",
    "    list_params, list_chains, index=None,rcm = rcm, it_mcmc=1000, increment=1, show_pbar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd54836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take a look at the samples for some of the machines \n",
    "idx_plot = list(range(0,len(list_chains), 1))\n",
    "\n",
    "for idx in idx_plot:\n",
    "\n",
    "    pc_proj = list_chains[idx][\"visible\"] @ V_dataT.mT\n",
    "    pc_proj = pc_proj.cpu().numpy()\n",
    "    plot_PCA(data_proj, pc_proj, [\"dataset\", f\"update {updates[idx]}\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa35617",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_z = compute_partition_function_ptt(list_params, list_chains)\n",
    "train_ll_ptt = []\n",
    "test_ll_ptt = []\n",
    "for i in range(len(list_params)):\n",
    "    train_ll_ptt.append(\n",
    "        compute_log_likelihood(\n",
    "            train_dataset.data, train_dataset.weights, list_params[i], log_z[i]\n",
    "        )\n",
    "    )\n",
    "    test_ll_ptt.append(\n",
    "        compute_log_likelihood(\n",
    "            test_dataset.data, test_dataset.weights, list_params[i], log_z[i]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de410873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the log partition functions saved during training\n",
    "ais_traj_train_ll = []\n",
    "ais_traj_test_ll = []\n",
    "for upd in updates:\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        params = load_params(filename, upd, device, dtype)\n",
    "        log_z = f[f\"update_{upd}\"][\"log_z\"][()]\n",
    "        if isinstance(log_z, np.ndarray):\n",
    "            log_z = log_z[0]\n",
    "        # Compute the associated log-likelihood\n",
    "        ais_traj_train_ll.append(\n",
    "            compute_log_likelihood(\n",
    "                train_dataset.data, train_dataset.weights, params, log_z\n",
    "            )\n",
    "        )\n",
    "        ais_traj_test_ll.append(\n",
    "            compute_log_likelihood(\n",
    "                test_dataset.data, test_dataset.weights, params, log_z\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa55d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rbms.partition_function.ais import compute_partition_function_ais\n",
    "from tqdm.notebook import tqdm\n",
    "all_train_ll_ais_temp = []\n",
    "all_test_ll_ais_temp = []\n",
    "for upd in tqdm(updates):\n",
    "    params = load_params(filename, upd, device, dtype)\n",
    "    log_z = compute_partition_function_ais(1000, 5000, params)\n",
    "    all_train_ll_ais_temp.append(compute_log_likelihood(train_dataset.data, train_dataset.weights, params, log_z))\n",
    "    all_test_ll_ais_temp.append(compute_log_likelihood(test_dataset.data, test_dataset.weights, params, log_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6083c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.plot(updates, train_ll_ptt, color=\"green\", label=\"PTT estimate\")\n",
    "ax.plot(\n",
    "    updates,\n",
    "    test_ll_ptt,\n",
    "    linestyle=\"dashed\",\n",
    "    color=\"green\",\n",
    ")\n",
    "ax.plot(\n",
    "    updates,\n",
    "    ais_traj_train_ll,\n",
    "    color=\"red\",\n",
    "    label=\"AIS traj estimate\",\n",
    ")\n",
    "ax.plot(\n",
    "    updates,\n",
    "    ais_traj_test_ll,\n",
    "    linestyle=\"dashed\",\n",
    "    color=\"red\",\n",
    ")\n",
    "ax.plot(\n",
    "    updates,\n",
    "    all_train_ll_ais_temp,\n",
    "    color=\"blue\",\n",
    "    label=r\"AIS $\\beta$ estimate\",\n",
    ")\n",
    "ax.plot(\n",
    "    updates,\n",
    "    all_test_ll_ais_temp,\n",
    "    linestyle=\"dashed\",\n",
    "    color=\"blue\",\n",
    ")\n",
    "ax.semilogx()\n",
    "ax.legend()\n",
    "ax.set_title(\"LL HGD\")\n",
    "ax.set_xlabel(\"Training time (gradient updates)\")\n",
    "ax.set_ylabel(\"LL (nats)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0296ec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
